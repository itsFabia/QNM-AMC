# Rolling / Expanding Window CV â€“ Design, BegrÃ¼ndung & Reflexion  
**Datum:** 2025-10-22  
**Autorin:** Fabia Holzer  

---

## 1. Ãœberblick

**Ziel:**  
Dieses Skript wurde entwickelt, um **Trainings- und Testaufteilungen fÃ¼r ein ML-basiertes Aktienmodell** zu erzeugen, die **zeitlich valide und reproduzierbar** sind.  
Es soll verhindern, dass das Modell versehentlich Informationen aus der Zukunft nutzt (Data Leakage) oder durch unfaire Splits verzerrt wird.  

**Kernidee:**  
Anstatt zufÃ¤lliger Folds arbeitet das Skript mit **rollierenden Zeitfenstern** â€“ jedes Fenster trainiert auf Vergangenheit und testet auf Zukunft.  
Das ist die einzige Methode, die einer realen Handelssituation entspricht:  
Man trainiert auf historische Daten und prÃ¼ft, wie gut das Modell auf neue, noch unbekannte Daten reagiert.  

---

## 2. Warum Rolling / Expanding Window?

### Problem bei klassischen Methoden:
- ZufÃ¤lliges Mischen von Zeitreihen verletzt die zeitliche KausalitÃ¤t.  
- Modelle lernen Muster, die in der Praxis **niemals im Voraus verfÃ¼gbar** wÃ¤ren.  
- Ohne Embargo Ã¼berlappen sich Training und Test oft (z. B. durch verzÃ¶gerte Marktreaktionen).  

### LÃ¶sung durch Rolling Windows:
- Das Modell trainiert auf einem festen Zeitraum (z. B. 3 Jahre) und wird dann auf den **nÃ¤chsten Monat** getestet.  
- Nach jedem Durchlauf wird das Fenster ein StÃ¼ck nach vorne verschoben â†’ realistische Simulation eines fortlaufenden Trainings.  
- Ein **Embargo von 5 Tagen** verhindert, dass Daten zu nahe beieinanderliegen (z. B. Gewinneffekte, Nachlaufeffekte).  

### Warum nicht Expanding Window?  
Rolling und Expanding werden beide unterstÃ¼tzt.  
- Rolling = konstanter Fokus, gut fÃ¼r Modelle mit begrenztem GedÃ¤chtnis.  
- Expanding = wachsendes Wissen, aber hÃ¶heres Risiko von Drift.  
FÃ¼r AMC-Modelle wurde Rolling gewÃ¤hlt, um Marktregime getrennt zu halten.

---

## 3. Cold-Start-Policy â€“ Wieso nÃ¶tig?

Nicht jeder Titel hat gleich lange Historie.  
Neue IPOs (z. B. **ALC** 2019, **AMRZ** 2025) verzerren die Statistik, wenn sie zu frÃ¼h einbezogen werden.  

**BegrÃ¼ndung:**  
Ein Modell, das nur wenige Dutzend Datenpunkte zu einem Ticker hat, kann keine stabilen Muster erkennen.  
Diese â€kaltenâ€œ Titel fÃ¼hren zu schwankenden Splits und erhÃ¶hen die Varianz.  

**LÃ¶sung:**  
Ticker werden erst berÃ¼cksichtigt, wenn sie im Trainingsfenster **mindestens 250 Tage** beobachtet wurden.  
Das ist ein pragmatischer Kompromiss: genug Daten, um Verhalten zu lernen â€“ aber keine kÃ¼nstliche Ausschliessung.  

---

## 4. Embargo & Purging â€“ Wieso 5 Tage?

In Finanzdaten wirken viele Ereignisse verzÃ¶gert.  
Wenn man direkt angrenzende Tage zwischen Train und Test verwendet, kann ein Modell indirekt **zukÃ¼nftige Information** nutzen â€“  
z. B. durch Ã¼berlappende RÃ¼ckberechnungen, glÃ¤ttende Fenster oder Korrelationen Ã¼ber Feiertage.  

Ein **Embargo von 5 Handelstagen** ist ein Erfahrungswert aus der Literatur (Lopez de Prado, *Advances in Financial Machine Learning*).  
Es eliminiert den grÃ¶ÃŸten Teil der ungewollten SignalÃ¼bertragung, ohne die StichprobengrÃ¶sse stark zu verringern.

---

## 5. Technische Struktur

| Komponente | Aufgabe | Warum diese Designentscheidung |
|-------------|----------|--------------------------------|
| `detect_ticker_column()` | Automatische Spaltenerkennung fÃ¼r Ticker. | Macht das Skript robust gegenÃ¼ber wechselnden Datenquellen. |
| `make_splits()` | Rolling/Expanding-Split mit Embargo. | VollstÃ¤ndig zeitreihensicher, ohne Randomisierung. |
| `Split.meta()` | Liefert Metriken und Verteilungen pro Split. | Transparenz Ã¼ber Datenbalance und Tickerabdeckung. |
| `write_log()` | Speichert Split-Infos als CSV. | Dient der spÃ¤teren Bias-Analyse und Dokumentation. |
| `save_split_indices()` | Exportiert Indizes (`.pkl`) fÃ¼r Reproduzierbarkeit. | Garantiert identische Splits fÃ¼r Scaling, Training und Backtesting. |

**Warum `.pkl` statt `.csv`?**  
Pickle-Dateien speichern Python-Objekte (hier: Integer-Indizes) verlustfrei.  
Sie sind kompakt, direkt in Pandas einlesbar und vermeiden Rundungsfehler oder Typkonvertierungen.

---

## 6. Beispielergebnis (Interpretation)

**Beispiel-Split:**  
- Train: 2017-12-27 â†’ 2020-12-27  
- Test: 2021-01-01 â†’ 2021-02-01  
- Embargo: 5 Tage  
- Train-Rows: 13â€™930, Test-Rows: 380  
- Ã˜ Ticker/Tag: 18.7  
- Splits gesamt: 57  

**Gedanke:**  
Diese Struktur imitiert den Ablauf eines echten Fondsmanagements:  
Alle 14 Tage oder 1 Monat wird neu evaluiert, auf Basis der letzten drei Jahre Marktgeschichte.  
Das schafft die Grundlage fÃ¼r eine stabile, inkrementelle Modellbewertung.

---

## 7. Warum Logging & Index-Export?

In Finanzprojekten mÃ¼ssen Ergebnisse **nachvollziehbar und prÃ¼fbar** sein â€“ regulatorisch wie analytisch.  
Deshalb wird jeder Split als Indexliste gespeichert:



So kann jedes nachfolgende Modul (z. B. Scaling, ML-Modelle, Backtest) exakt dieselben Daten verwenden.  
Wenn ein Modell spÃ¤ter verbessert wird, bleibt der Vergleich **methodisch fair**.

---

## 8. Kritische Reflexion

**StÃ¤rken:**
- Zeitlich saubere Trennung â†’ kein Data Leakage.  
- Reproduzierbare Struktur â†’ Backtests werden vergleichbar.  
- Cold-Start-Filterung â†’ realistischere Modellbasis.  
- ModularitÃ¤t â†’ einfach in weitere Pipelines integrierbar.

**SchwÃ¤chen:**
- SpÃ¤te IPOs (z. B. AMRZ) fÃ¼hren zu stark schrumpfenden DatensÃ¤tzen.  
- Keine Gewichtung nach LiquiditÃ¤t oder Handelsvolumen.  
- Rolling-Fenster kÃ¶nnen driften, wenn Makroregime stark wechseln.  
- Splits sind fix â†’ keine adaptive Optimierung nach MarktvolatilitÃ¤t.

**Gedanke:**  
Das Skript ist bewusst konservativ â€“ lieber weniger, aber saubere Daten,  
als hohe Varianz durch fragwÃ¼rdige â€historischeâ€œ Datenpunkte.  
Diese Strenge bildet das Fundament fÃ¼r glaubwÃ¼rdige Performanceanalysen.

---

## 9. NÃ¤chste Schritte (To-Dos)

1. **Feature-Scaling (log1p + z-Score):**  
   Aufbau eines Moduls `scale_and_save.py`, das pro Split und Ticker normalisiert  
   (Train-Stats â†’ Test Ã¼bernehmen).

2. **Backtesting-Logik:**  
   Entwicklung einer Simulationsumgebung, die die Splits nutzt,  
   um Handelsregeln (Ranking, Gewichtung, Haltedauer, Drawdown-Limits) zu testen.

3. **Feature-Drift-Analyse:**  
   Ermittlung, welche Features Ã¼ber Zeit an StabilitÃ¤t verlieren  
   â†’ wichtig fÃ¼r langfristig robuste Modelle.

4. **Performance-Monitoring:**  
   Sammlung der Split-Ergebnisse zu globalen Kennzahlen:  
   Information Coefficient, Precision@K, Sharpe Ratio, Max Drawdown.

5. **Automatisierung:**  
   Integration aller Schritte (Bias Review â†’ Splits â†’ Scaling â†’ Model â†’ Backtest â†’ Report)  
   in eine einheitliche Pipeline fÃ¼r kontinuierliche Modellbewertung.

---

## 10. Fazit

Dieses Skript ist die **methodische Basis** der gesamten AMC-Modellphase.  
Es trennt sauber Vergangenheit und Zukunft, erlaubt reproduzierbare Experimente  
und schafft damit die Grundlage fÃ¼r statistisch belastbare Investmententscheidungen.

Kurz gesagt:  
ğŸ‘‰ **Ohne sauberes Splitting ist jede Backtest-Performance wertlos.**  
Dieses Skript sorgt dafÃ¼r, dass das Fundament stimmt â€“ bevor das Modell bewertet wird.
